The wandb report link is:

1. Question 1
    1. Here we have created a class seq2seq, in this class we have created a function "create_model" which will return a model based on different parameters which are passed to seq2seq class.
    2. We have written our code as per the requirements which is asked in the question
    3. Link for the .ipynb file: https://colab.research.google.com/drive/1PtGYeH0gD-SpFMN5LbgAYTNT-SFWIcnc?usp=sharing
2. Question 2
    1. In this question, we have setup the sweep on the above code.
    2. Here we are adding the parameters like Dropout,Batch size,Epochs,Encoder_layer_size,Decoder_layer_size,Emebdding size, Cell type, and latent dimension size.
    3. Then we have run the sweep in wandb.
    4. Link for the .ipynb file: https://colab.research.google.com/drive/1JsFpoG-7shQIafy-4HU3K4jLadoR9B5q?usp=sharing
3. Question 4
    1. Here we have run the best seq2seq model on the test data. We got an accuracy of 41.67% accuracy on the unseen test data.
    2. The prediction_vanilla file is pushed in the github. It contains the predictions made by the our best vanilla seq2seq model.
    3. Link for the .ipynb file: https://colab.research.google.com/drive/1UvYNLVks2PdrcDd7Y2TTlwmkw-J5hLVT?usp=sharing
    
 4. Question 5 
    1. Here we have implemented the attention mechanism and ran sweep over the code.
    2. We got test accuracy as 46.058% with our best model.
    3. The prediction_attention file is pushed in the github. It contains the predictions made by the our best model with attention mechanism.
    4. We have added the heatmap images in 3\*3 grid to the report.
    5. Link for the .ipynb file: https://colab.research.google.com/drive/10k1_9Yqhg9HiktsVMWt5aT78FirhlAIe?usp=sharing

5. Question 6  
    1.
    2. 
    3. Link for the .ipynb file: https://colab.research.google.com/drive/1DHQADAC7QkNGKgYKxIaewqxhpa-sggNN?usp=sharing 

**NOTE:** The code pushed from the system of CS20M009 is visible as "commited by username unknown".
