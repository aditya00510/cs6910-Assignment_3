{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment3_Q6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95a074430c20465582ab531288dd62c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_adb6fb1ae3e7495bb4276ffa31bd300e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a17226a013634dc89580b8ea04c67f90",
              "IPY_MODEL_0e66a015e6734a94922dee4ec9e58f9c"
            ]
          }
        },
        "adb6fb1ae3e7495bb4276ffa31bd300e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a17226a013634dc89580b8ea04c67f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_207a33db04824867b738551a01ee9833",
            "_dom_classes": [],
            "description": "idx",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f94703c64967451abe323fe0d2c6deab"
          }
        },
        "0e66a015e6734a94922dee4ec9e58f9c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "<text style=color:#000;background-color:#85c2e1;font-size:30px>/start/ </text><text style=color:#000;background-color:#85c2e1;font-size:30px>a </text><text style=color:#000;background-color:#85c2e1;font-size:30px>d </text><text style=color:#000;background-color:#85c2e1;font-size:30px>i </text><text style=color:#000;background-color:#85c2e1;font-size:30px>t </text><text style=color:#000;background-color:#85c2e1;font-size:30px>y </text><text style=color:#000;background-color:#85c2e1;font-size:30px>a </text><text style=color:#000;background-color:#f42e2e;font-size:31px>/end/ </text>",
                "text/plain": "<IPython.core.display.HTML object>"
              },
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "\n\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "<text style=color:#000;background-color:#85c2e1;font-size:30px>అ </text><text style=color:#000;background-color:#85c2e1;font-size:30px>డ </text><text style=color:#000;background-color:#85c2e1;font-size:30px>ి </text><text style=color:#000;background-color:#85c2e1;font-size:30px>త </text><text style=color:#000;background-color:#85c2e1;font-size:30px>్ </text><text style=color:#000;background-color:#f42e2e;font-size:31px>య </text>",
                "text/plain": "<IPython.core.display.HTML object>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_3832a3ac52eb474e80a2e3ed2fba9947",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "207a33db04824867b738551a01ee9833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f94703c64967451abe323fe0d2c6deab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3832a3ac52eb474e80a2e3ed2fba9947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18sd1CLFkQ8j",
        "outputId": "179f7015-5b59-46d1-ea5e-664a207f82a8"
      },
      "source": [
        "!curl --header \"Host: storage.googleapis.com\" --header \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36 Edg/89.0.774.77\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-US,en;q=0.9\" --header \"Referer: https://github.com/google-research-datasets/dakshina\" \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\" -L -o \"dakshina_dataset_v1.0.tar\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1915M  100 1915M    0     0   107M      0  0:00:17  0:00:17 --:--:-- 30.4M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7aWLNxClEuh"
      },
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/dakshina_dataset_v1.0.tar\",'/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMMAnCymXuj4"
      },
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense,LSTM,GRU,SimpleRNN,Input,Dropout,TimeDistributed,RepeatVector,dot,BatchNormalization,concatenate,multiply,Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Layer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.optimizers import Adam,Adadelta,Nadam,SGD\n",
        "from keras.losses import SparseCategoricalCrossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7wOWJLkGXap"
      },
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = tf.reduce_sum((attention_weights * values), axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do_8GHLqR0jG"
      },
      "source": [
        "class Encoder(Model):\n",
        "  def __init__(self,cell,vocab_size, embedding_dim, latent_dim, batch_size,initializer,dropouts):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.cell = cell\n",
        "    self.batch_size = batch_size\n",
        "    self.latent_dim = latent_dim\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    if cell == \"gru\":\n",
        "        self.gru = GRU(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"lstm\":\n",
        "        self.lstm = LSTM(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"rnn\":\n",
        "        self.rnn = SimpleRNN(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    if self.cell == \"gru\":\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "    elif self.cell == \"lstm\":\n",
        "        output, state, state_c= self.lstm(x, initial_state=hidden)\n",
        "    elif self.cell == \"rnn\":\n",
        "        output, state = self.rnn(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "      if self.cell == 'lstm':\n",
        "          return [tf.zeros((self.batch_size, self.latent_dim)),tf.zeros((self.batch_size, self.latent_dim))]\n",
        "      return tf.zeros((self.batch_size, self.latent_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN08nKjdT0PO"
      },
      "source": [
        "class Decoder(Model):\n",
        "  def __init__(self, cell, vocab_size, embedding_dim, latent_dim, batch_size,initializer,dropouts):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.cell = cell\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = BahdanauAttention(latent_dim)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    self.dense = Dense(vocab_size)\n",
        "    if cell == \"gru\":\n",
        "        self.gru = GRU(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"lstm\":\n",
        "        self.lstm = LSTM(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"rnn\":\n",
        "        self.rnn = SimpleRNN(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    if self.cell == \"gru\":\n",
        "        output, state = self.gru(x)\n",
        "    elif self.cell == \"lstm\":\n",
        "        output, state,state_c = self.lstm(x)\n",
        "    elif self.cell == \"rnn\":\n",
        "        output, state = self.rnn(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.dense(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCl6q3-O5wS"
      },
      "source": [
        "class Attention:\n",
        "    def __init__(self,cell,embedding_size,latent_dim,optimizer,dropouts,batch_size,epochs,initializer):\n",
        "        self.cell = cell\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.opt = optimizer\n",
        "        self.dropouts=dropouts\n",
        "        self.initializer=initializer\n",
        "\n",
        "    @tf.function()    \n",
        "    def train_step(self, inp, targ, enc_hidden):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([self.input_token_index['\\t']] * self.BATCH_SIZE, 1)\n",
        "\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += self.loss_function(targ[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables + self.decoder.attention.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        return batch_loss\n",
        "\n",
        "    def get_data(self,path):\n",
        "        d = pd.read_csv(path,sep=\"\\t\",header=None,error_bad_lines=False)\n",
        "        d = d.dropna()\n",
        "\n",
        "        decoder_target_data = np.zeros((d.shape[0],self.max_length_y,self.decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "        for i,target_text in enumerate(d[0]):\n",
        "            target_text = '\\t'+target_text+'\\n'\n",
        "            for t, char in enumerate(target_text):\n",
        "                if t > 0:\n",
        "                    decoder_target_data[i, t - 1, self.target_token_index[char]] = 1.0\n",
        "            decoder_target_data[i, t:, self.target_token_index[\"\\n\"]] = 1.0\n",
        "\n",
        "        return ([[self.input_token_index[letter] for letter in list('\\t'+word+'\\n')] for word in d[1]]),\\\n",
        "                ([[self.target_token_index[letter] for letter in list('\\t'+word+'\\n')] for word in d[0]]),decoder_target_data\n",
        "\n",
        "    def create_vocab(self,path):\n",
        "        d = pd.read_csv(path,sep=\"\\t\",header=None,error_bad_lines=False)\n",
        "        d = d.dropna()\n",
        "\n",
        "        x = [list('\\t'+word+'\\n') for word in np.array(d[1])]\n",
        "        y = [list('\\t'+word+'\\n') for word in np.array(d[0])]\n",
        "\n",
        "        telugu_vocab = set()\n",
        "        english_vocab = set()\n",
        "\n",
        "        for word in x:\n",
        "            for char in word:\n",
        "                english_vocab.add(char)\n",
        "\n",
        "        for word in y:\n",
        "            for char in word:\n",
        "                telugu_vocab.add(char)\n",
        "\n",
        "        telugu_list = sorted(list(telugu_vocab))\n",
        "        english_list = sorted(list(english_vocab))\n",
        "\n",
        "        max_length_x = (np.max([len(i) for i in x]))\n",
        "        max_length_y = (np.max([len(i) for i in y]))\n",
        "\n",
        "        return telugu_list,english_list,max_length_x,max_length_y    \n",
        "\n",
        "    def create_data(self):\n",
        "        train_path = \"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\"\n",
        "        cv_path = \"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "        test_path = \"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\"\n",
        "\n",
        "        telugu_list,english_list,self.max_length_x,self.max_length_y = self.create_vocab(train_path)\n",
        "        self.encoder_tokens = len(english_list)\n",
        "        self.decoder_tokens = len(telugu_list)\n",
        "\n",
        "        # Dict for char to index\n",
        "        self.input_token_index = dict([(char, i) for i, char in enumerate(english_list)])\n",
        "        self.target_token_index = dict([(char, i) for i, char in enumerate(telugu_list)])\n",
        "\n",
        "        # Dict for index to char\n",
        "        self.inv_input_token_index = dict({(value,key) for key,value in self.input_token_index.items()})\n",
        "        self.inv_target_token_index = dict({(value,key) for key,value in self.target_token_index.items()})\n",
        "\n",
        "        encoder_train,decoder_train,self.decoder_target_train = self.get_data(train_path)\n",
        "        encoder_cv,decoder_cv,self.decoder_target_cv = self.get_data(cv_path)\n",
        "        encoder_test,decoder_test,self.decoder_target_test = self.get_data(test_path)\n",
        "\n",
        "\n",
        "        self.encoder_train = sequence.pad_sequences(encoder_train,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_train = sequence.pad_sequences(decoder_train,maxlen=self.max_length_y,padding=\"post\")\n",
        "        self.encoder_cv = sequence.pad_sequences(encoder_cv,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_cv = sequence.pad_sequences(decoder_cv,maxlen=self.max_length_y,padding=\"post\")\n",
        "        self.encoder_test = sequence.pad_sequences(encoder_test,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_test = sequence.pad_sequences(decoder_test,maxlen=self.max_length_y,padding=\"post\")\n",
        "\n",
        "        self.BUFFER_SIZE = len(self.encoder_train)        \n",
        "        self.steps_per_epoch = len(self.encoder_train)//self.BATCH_SIZE\n",
        "\n",
        "        self.dataset = tf.data.Dataset.from_tensor_slices((self.encoder_train, self.decoder_train)).shuffle(self.BUFFER_SIZE)\n",
        "        self.dataset = self.dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "\n",
        "    def loss_function(self,real, pred):\n",
        "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "        loss_ = self.loss_object(real, pred)\n",
        "        loss_ *= tf.cast(mask, dtype=loss_.dtype)\n",
        "\n",
        "        return tf.reduce_mean(loss_)\n",
        "\n",
        "    def run(self):\n",
        "        # Compile & run training\n",
        "\n",
        "        if self.opt == \"nadam\":\n",
        "            self.optimizer = Nadam()\n",
        "        elif self.opt == \"sgd\":\n",
        "            self.optimizer = SGD()\n",
        "        elif self.opt == \"adadelta\":\n",
        "            self.optimizer = Adadelta()\n",
        "        else:\n",
        "            self.optimizer = Adam()\n",
        "\n",
        "        self.loss_object = SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
        "        \n",
        "        self.encoder = Encoder(self.cell,self.encoder_tokens, self.embedding_dim, self.latent_dim, self.BATCH_SIZE, self.initializer,self.dropouts)\n",
        "        self.decoder = Decoder(self.cell,self.decoder_tokens, self.embedding_dim, self.latent_dim, self.BATCH_SIZE, self.initializer,self.dropouts)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            enc_hidden = self.encoder.initialize_hidden_state()\n",
        "            total_loss = 0\n",
        "            \n",
        "            for (batch, (inp, targ)) in enumerate(self.dataset.take(self.steps_per_epoch)):\n",
        "                batch_loss = self.train_step(inp, targ, enc_hidden)\n",
        "                total_loss += batch_loss \n",
        "\n",
        "            print(f'Epoch {epoch+1} Loss {total_loss/self.steps_per_epoch:.4f}   ')        \n",
        "\n",
        "\n",
        "    def evaluate(self,sentence_vect,attention=False):\n",
        "        if attention:\n",
        "            att_plot = np.zeros((self.max_length_y,self.max_length_x))\n",
        "        inputs = tf.convert_to_tensor(sentence_vect)\n",
        "        inputs = tf.expand_dims(inputs,0)\n",
        "        result = ''\n",
        "        if self.cell == \"lstm\":\n",
        "            hidden = [tf.zeros((1, self.latent_dim)),tf.zeros((1, self.latent_dim))]\n",
        "        else:\n",
        "            hidden = [tf.zeros((1, self.latent_dim))]\n",
        "        enc_out, enc_hidden = self.encoder(inputs, hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([self.target_token_index['\\t']], 0)\n",
        "\n",
        "        for t in range(self.max_length_y):\n",
        "            predictions, dec_hidden, attention_weights = self.decoder(dec_input, dec_hidden, enc_out)\n",
        "            \n",
        "            if attention:\n",
        "                att_plot[t] = (tf.reshape(attention_weights,(-1,))).numpy()\n",
        "\n",
        "            predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "            if self.inv_target_token_index[predicted_id] != \"\\n\":\n",
        "                result += self.inv_target_token_index[predicted_id]\n",
        "            else:\n",
        "                if attention:\n",
        "                    return result,att_plot\n",
        "                return result\n",
        "\n",
        "            dec_input = tf.expand_dims([predicted_id], 0) \n",
        "\n",
        "        if attention:\n",
        "            return result,att_plot\n",
        "        return result\n",
        "\n",
        "    def percentage_of_correct_test_predictions(self):\n",
        "        count = 0\n",
        "        for i in range(len(self.decoder_test)):\n",
        "            actual = \"\"\n",
        "            for x in self.decoder_test[i][1:]:\n",
        "                if self.inv_target_token_index[x]==\"\\n\":\n",
        "                    break\n",
        "                actual += self.inv_target_token_index[x]\n",
        "\n",
        "            pred = self.evaluate(self.encoder_test[i])\n",
        "            if (actual==pred):\n",
        "                count+=1\n",
        "                \n",
        "        return count/len(self.decoder_test)\n",
        "\n",
        "    def percentage_of_correct_cv_predictions(self):\n",
        "        count = 0\n",
        "        for i in range(len(self.decoder_cv)):\n",
        "            actual = \"\"\n",
        "            for x in self.decoder_cv[i][1:]:\n",
        "                if self.inv_target_token_index[x]==\"\\n\":\n",
        "                    break\n",
        "                actual += self.inv_target_token_index[x]\n",
        "\n",
        "            pred = self.evaluate(self.encoder_cv[i])\n",
        "            if (actual==pred):\n",
        "                count+=1\n",
        "\n",
        "        return count/len(self.decoder_cv)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usd21800Pq0a"
      },
      "source": [
        "def translate(sent,attention=False,print_out=True,print_plot=False):\n",
        "  sent = \"\\t\"+sent+\"\\n\"\n",
        "  sent_vec = [s2s.input_token_index[i] for i in sent]\n",
        "  sent_vec = sequence.pad_sequences([sent_vec],maxlen=s2s.max_length_x,padding=\"post\")\n",
        "\n",
        "  if attention:\n",
        "      pred,attention = s2s.evaluate(sent_vec[0],True)\n",
        "      if print_out:\n",
        "        print(\"Input:\",sent)\n",
        "        print(\"Output:\",pred)\n",
        "      \n",
        "      if print_plot:\n",
        "        attention_plot(attention[:len(pred),:len(sent)],sent,pred)\n",
        "\n",
        "      return attention[:len(pred),:len(sent)],pred\n",
        "      \n",
        "  else:\n",
        "      pred = s2s.evaluate(sent_vec[0],False)\n",
        "      print(\"Input:\",sent)\n",
        "      print(\"Output:\",pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMvqnySqB7Xk"
      },
      "source": [
        "import seaborn as sb\n",
        "\n",
        "def attention_plot(attention,actual,pred):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    img = sb.heatmap(attention,cbar=False)\n",
        "    ax.set_xticklabels(['start']+list(actual[1:-1])+['end'])\n",
        "    ax.set_yticklabels(list(pred))\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9i3c7pNv7L2"
      },
      "source": [
        "**Best Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2BXOlr0VS2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c343d303-429d-4e4a-d1f9-2b3a9ea917fe"
      },
      "source": [
        "s2s = Attention(\"gru\",8,256,\"nadam\",0.2,32,5,\"orthogonal\")\n",
        "s2s.create_data()\n",
        "s2s.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.8522   \n",
            "Epoch 2 Loss 0.2910   \n",
            "Epoch 3 Loss 0.2299   \n",
            "Epoch 4 Loss 0.1839   \n",
            "Epoch 5 Loss 0.1535   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTh9JEJ2_Xy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5382f895-465c-4f71-fa5c-556a776e26a8"
      },
      "source": [
        "cv_acc = s2s.percentage_of_correct_cv_predictions()\n",
        "\n",
        "print(\"Cross Validation Word Accuracy is\",cv_acc*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Word Accuracy is 43.85007918352983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlj2fB6bWTos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8106c98c-ddfe-4dd8-b89d-620d79aba769"
      },
      "source": [
        "test_acc = s2s.percentage_of_correct_test_predictions()\n",
        "\n",
        "print(\"Test Word Accuracy is\",test_acc*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Word Accuracy is 46.05881329389246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMsI8VxDXW_i"
      },
      "source": [
        "# Type a word to translate to telugu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWAmjzIHAz3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e63a3b2c-b8f8-4cc7-8471-01c63d7751a0"
      },
      "source": [
        "input_text = 'angeekaaram' #@param {type:\"string\"}\n",
        "s2s.translate(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: angeekaaram\n",
            "Output: అంగీకారం\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvexXdsgz3zp"
      },
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld5fiQt88-CK"
      },
      "source": [
        "def cstr(s,flag=False, color='black'):\n",
        "  if flag: \n",
        "    return \"<text style=color:#000;background-color:{};font-size:31px>{} </text>\".format(color, s)\n",
        "    \n",
        "  return \"<text style=color:#000;background-color:{};font-size:30px>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) if ci != '#f42e2e' else cstr(ti,True,color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dITgvrd9SFyx"
      },
      "source": [
        "def visualize(input, attention_matrix, target_char_index):\n",
        "  text_colours = []\n",
        "\n",
        "  for i in range(len(input)+2):\n",
        "    if i == 0:\n",
        "      text = (\"/start/\",get_clr(attention_matrix[target_char_index][i]))\n",
        "    elif i == len(input)+1:\n",
        "      text = (\"/end/\",get_clr(attention_matrix[target_char_index][i]))\n",
        "    else:\n",
        "      text = (input[i-1], get_clr(attention_matrix[target_char_index][i]))\n",
        "    \n",
        "    text_colours.append(text)\n",
        "  print_color(text_colours)\n",
        "\n",
        "def visualize_out(input,idx):\n",
        "  text_colours = []\n",
        "  for i in range(len(input)):\n",
        "    \n",
        "    if i==idx:\n",
        "      text = (input[i],'#f42e2e')\n",
        "    else:\n",
        "      text = (input[i],'#85c2e1')\n",
        "    text_colours.append(text)\n",
        "  print_color(text_colours)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGweaP6YUl9"
      },
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8plMh5M-G22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "95a074430c20465582ab531288dd62c3",
            "adb6fb1ae3e7495bb4276ffa31bd300e",
            "a17226a013634dc89580b8ea04c67f90",
            "0e66a015e6734a94922dee4ec9e58f9c",
            "207a33db04824867b738551a01ee9833",
            "f94703c64967451abe323fe0d2c6deab",
            "3832a3ac52eb474e80a2e3ed2fba9947"
          ]
        },
        "cellView": "form",
        "outputId": "b8d4bd0b-14ca-4ee7-c95b-77138ff7fe98"
      },
      "source": [
        "input_word = 'aditya' #@param {type:\"string\"}\n",
        "attention_matrix,pred = translate(input_word,attention=True,print_out=False)\n",
        "\n",
        "def get_color_code(idx):\n",
        "    print()\n",
        "    visualize(input_word,attention_matrix,idx)\n",
        "    print()\n",
        "    print()\n",
        "    visualize_out(pred,idx)\n",
        "\n",
        "  \n",
        "interact(get_color_code, idx=(0,len(pred)-1));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a074430c20465582ab531288dd62c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=2, description='idx', max=5), Output()), _dom_classes=('widget-interact'…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOb_20Fa90Uj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARhu9Sj90RJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXppa-pI90Ok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6Ew5kpzYS23"
      },
      "source": [
        "word = 'angeekarinchaadu' #@param {type:\"string\"}\n",
        "attention_matrix,pred = translate(word,attention=True,print_out=False)\n",
        "\n",
        "def get_color_code(idx):\n",
        "    visualize(word,attention_matrix,idx)\n",
        "    print()\n",
        "    print()\n",
        "    visualize_out(pred,idx)\n",
        "\n",
        "  \n",
        "interact(get_color_code, idx=(0,len(pred)-1));"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}